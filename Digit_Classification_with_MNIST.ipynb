{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Classification_with_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtz0sXqUIJvLU61Kk213+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsfwalters/NEU-OB-MLP/blob/main/Digit_Classification_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Classification\n",
        "In this Colab notebook, you will build and train a neural network to classify a \n",
        "handwritten digit (zero through nine) in an image.  Run each cell by clicking on the play button or using keys `Shift+Enter`.  There will be some text hints and questions to help guide you through the notebook."
      ],
      "metadata": {
        "id": "ekwZYGQW32FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries for this library\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.container import ModuleList\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "widWrvRqcto0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download Data\n",
        "In this section, you will download the datasets with thousands of handwritten digits.  The digits in the training set come from US Census Bureau employees and the digits in the test set come from US high school students.  There are several plots that will be generated to help you get a sense of the data."
      ],
      "metadata": {
        "id": "0tLaZZQLijXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# download train and test sets\n",
        "train_data = MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "test_data = MNIST(root='data', train=False, transform=ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "lVWMPvjAipP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Why do you need separate data for training and testing? What would happen if we only used training data?"
      ],
      "metadata": {
        "id": "7QymCYaW4ymf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print stats about datasets\n",
        "print(f'There are {len(train_data)} data points in train set' \\\n",
        "      f' and {len(test_data)} data points in test set.')\n",
        "\n",
        "# plot distribution of labels in train and test set\n",
        "plt.figure()\n",
        "plt.hist(train_data.targets, torch.arange(10)-0.7, \n",
        "         rwidth=0.4, density=True, label='Train Data')\n",
        "plt.hist(test_data.targets, torch.arange(10)-0.3, \n",
        "         rwidth=0.4, density=True, label='Test Data')\n",
        "plt.ylabel('Fraction of Examples', fontsize=14)\n",
        "plt.xticks(torch.arange(0,10))\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=14)\n",
        "plt.title('Fraction of Digit Examples in Datasets', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8HoURYggDQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] What do you think would happen if there were way more examples of one digit than another?\n"
      ],
      "metadata": {
        "id": "HPsMTo5hkxlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(train_data, test_data, label=0):\n",
        "  f, ax = plt.subplots(2, 10, figsize=(10,2))\n",
        "  f.subplots_adjust(0.1, 0, 1, 0.8, wspace=0.01, hspace=0.3)\n",
        "\n",
        "  # find data points with correct label\n",
        "  train_imgs = train_data.data[train_data.targets == label]\n",
        "  test_imgs = test_data.data[test_data.targets == label]\n",
        "\n",
        "  for i in range(10):\n",
        "    ax[0,i].imshow(train_imgs[i], cmap='gray')\n",
        "    ax[0,i].axis('off')\n",
        "    ax[1,i].imshow(test_imgs[i], cmap='gray')\n",
        "    ax[1,i].axis('off')\n",
        "\n",
        "  plt.suptitle(f'Examples of y = {label}', fontweight='bold', fontsize=20)\n",
        "  ax[0,0].text(-10, 16, 'Train Images', ha='right', fontstyle='italic', fontsize=16)\n",
        "  ax[1,0].text(-10, 16, 'Test Images', ha='right', fontstyle='italic', fontsize=16)\n",
        "  plt.show()\n",
        "\n",
        "# try changing the DIGIT to see examples of different digits\n",
        "DIGIT = 0\n",
        "plot_examples(train_data, test_data, DIGIT)"
      ],
      "metadata": {
        "id": "20BBNo8PjRH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Which digit do you think will be the hardest to recognize? ( change `DIGIT` in the above cell to see more examples)\n",
        "\n",
        "[__Question__] What kind of variations do you see between digits in the train data and test data? What kind of accuracy do you think will be possible?"
      ],
      "metadata": {
        "id": "NafQMROYlPMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model\n",
        "Now, we create the neural network."
      ],
      "metadata": {
        "id": "Fyk0M-IbilA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the image has 28^2 values\n",
        "INPUT_SIZE = 28 * 28\n",
        "\n",
        "# there are 10 digits to classify\n",
        "OUTPUT_SIZE = 10\n",
        "\n",
        "# this changes how much learning capacity the model will have\n",
        "# increasing this number will slow down training\n",
        "HIDDEN_SIZE = 128\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    nn.ReLU(True),\n",
        "    nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),\n",
        "    nn.ReLU(True),\n",
        "    # nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),\n",
        "    # nn.ReLU(True),\n",
        "    nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        ").cuda()\n",
        "\n",
        "# function to reset weights of the model\n",
        "def reset_weights(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "    m.reset_parameters()\n",
        "\n",
        "# The number of learnable values within the network\n",
        "num_weights =  sum(p.numel() for p in model.parameters())\n",
        "print(f\"This model has {num_weights:,} weights.\")\n",
        "\n",
        "# For comparison, here are the estimated number of neurons in different animals\n",
        "#   fruit fly :   100,000\n",
        "#   honey bee :   960,000\n",
        "#   frog :     16,000,000\n",
        "#   dog :   2,253,000,000\n",
        "#   human: 86,000,000,000\n",
        "# [source](https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons)"
      ],
      "metadata": {
        "id": "NV_JWMKlnHHA",
        "outputId": "6f3ba40f-6f6d-41ae-8587-c837a1fedaca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model has 118,282 weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Optional__] If you have extra time, you can try changing the network and see what effects it has on the accuracy.  For instance, `HIDDEN_SIZE` can be changed or you could uncomment lines 17 and 18 to add an additional layer."
      ],
      "metadata": {
        "id": "Tp6JDYnMmSca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train\n",
        "Now, we will train the model by iterating over the dataset and updating the weights of the model to improve the accuracy.  "
      ],
      "metadata": {
        "id": "FhHFbZUOimy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data, test_data, num_epochs, batch_size, learning_rate):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # create dataloaders\n",
        "  train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  log = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    t = time.perf_counter()\n",
        "\n",
        "    train_losses = []\n",
        "    for imgs, labels in train_dataloader:\n",
        "      imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred_labels = model(imgs)\n",
        "      loss = nn.CrossEntropyLoss()(pred_labels, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      train_losses.append(loss.item())\n",
        "      train_losses.append(loss.item())\n",
        "    \n",
        "    test_losses = []\n",
        "    for imgs, labels in test_dataloader:\n",
        "      imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "      pred_labels = model(imgs)\n",
        "      test_losses.append(loss.item())\n",
        "    \n",
        "    elapsed_time = time.perf_counter() - t\n",
        "    log.append(dict(epoch=epoch,\n",
        "                    train_loss= sum(train_losses) / len(train_losses),\n",
        "                    test_loss= sum(test_losses) / len(test_losses),\n",
        "                    elapsed_time= elapsed_time,\n",
        "    ))\n",
        "    print('Epoch {epoch}: TRAIN LOSS={train_loss:.5f} | TEST LOSS={test_loss:.5f} | '\n",
        "          'time={elapsed_time:.1f} s'.format(**log[-1]))\n",
        "\n",
        "  return model, log\n",
        "  \n",
        "def plot_learning_curves(log):\n",
        "  f = plt.figure()\n",
        "  f.subplots_adjust(0.1, 0.1, 0.9, 0.9, wspace=0.2)\n",
        "\n",
        "  epochs = [l['epoch'] for l in log]\n",
        "  train_loss = [l['train_loss'] for l in log]\n",
        "  test_loss = [l['test_loss'] for l in log]\n",
        "\n",
        "  plt.plot(epochs, train_loss, label='train')\n",
        "  plt.plot(epochs, test_loss, label='test')\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('Epoch', fontsize=16)\n",
        "  plt.ylabel('Loss', fontsize=16)\n",
        "  plt.legend(loc='upper right', fontsize=14)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NW1l4cpmj8CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These values are called hyperparameters and are the 'dials' that we can turn \n",
        "# to try to improve the model's performance\n",
        "\n",
        "BATCH_SIZE = 512 # how many examples are shown to the network at a time\n",
        "NUM_EPOCHS = 10 # number of times the model sees the full dataset\n",
        "LEARNING_RATE = 0.005 # how much the neurons adjust their weights\n",
        "\n",
        "model.apply(reset_weights)\n",
        "\n",
        "# this trains the model, it should take around 5 seconds per epoch\n",
        "model, log = train_model(model, train_data, test_data, \n",
        "                         NUM_EPOCHS, BATCH_SIZE, LEARNING_RATE)\n",
        "\n",
        "plot_learning_curves(log)"
      ],
      "metadata": {
        "id": "2f4mgyXpmxQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Do you observe [overfitting](https://www.ibm.com/cloud/learn/overfitting)? \n",
        "\n",
        "[__Optional__] Try adjusting the hyperparameters.  For example, what happens when you double `LEARNING_RATE`?"
      ],
      "metadata": {
        "id": "5t_O937p9kqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluate Trained Model\n",
        "Now we find the accuracy of the trained model at classifying digits. By looking at some example predictions, you may get some insight into why the model makes mistakes."
      ],
      "metadata": {
        "id": "CpiqX3QQinnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_statistics(model, data):\n",
        "  labels = data.targets\n",
        "  loader = DataLoader(data, batch_size=256)\n",
        "\n",
        "  pred_labels = []\n",
        "  for imgs, _ in loader:\n",
        "    pred_labels.append(model(imgs.cuda()).max(1)[1].detach().cpu())\n",
        "\n",
        "  pred_labels = torch.cat(pred_labels)\n",
        "\n",
        "  is_correct = (labels == pred_labels).float()\n",
        "  for i in range(10):\n",
        "    ind = labels == i\n",
        "    acc = torch.mean( is_correct[ind] )\n",
        "    print(f'    {i}: {acc:.2%} accuracy')\n",
        "\n",
        "  total_acc = torch.mean( is_correct )\n",
        "  print(f'Total: {total_acc:.2%} accuracy')\n",
        "\n",
        "\n",
        "def plot_predictions(model, data):\n",
        "  from matplotlib.patches import Rectangle\n",
        "  loader = DataLoader(data, batch_size=24, shuffle=True)\n",
        "\n",
        "  imgs, labels = next(iter(loader))\n",
        "  pred_labels = model(imgs.cuda()).max(1)[1].detach().cpu()\n",
        "\n",
        "  f, axs = plt.subplots(4,6, figsize=(10, 8))\n",
        "  f.subplots_adjust(0,0,1,1, wspace=0.1, hspace= 0.2)\n",
        "\n",
        "  for i, ax in enumerate(axs.flatten()):\n",
        "    ax.imshow(imgs[i,0], cmap='gray')\n",
        "    color = 'g' if pred_labels[i] == labels[i] else 'r'\n",
        "    ax.add_patch(Rectangle((0,0), 1, 1, fc='none', ec=color, lw=10, transform=ax.transAxes))\n",
        "\n",
        "    ax.set_title(f'pred={pred_labels[i]} [{labels[i]}]', fontsize=16)\n",
        "    ax.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Md-XbSMNvMNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = test_data \n",
        "# DATA = train_data\n",
        "\n",
        "compute_statistics(model, DATA)"
      ],
      "metadata": {
        "id": "GGKOuhpAwwjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Are there any digits that the model is less accurate at predicting? Is there an explanation for this?\n",
        "\n",
        "[__Question__] What accuracy would you expect if the model had not learned anything?\n",
        "\n",
        "[__Question__] Do you think the accuracy would be higher or lower for images from the training data? (try it yourself by setting `DATA` to `train_data` above) "
      ],
      "metadata": {
        "id": "V6K-eG4e4vHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running this cell again will show new examples\n",
        "plot_predictions(model, test_data)"
      ],
      "metadata": {
        "id": "KSYUvEkBwzjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Do you see any patterns in the wrong predictions?\n",
        "\n",
        "[__Question__] Do you think the model is as good as a human at recognizing digits?"
      ],
      "metadata": {
        "id": "-CjU5pxB3K_q"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clothing_Classification_with_Neural_Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqeqTJdU/skIC2YElBz0Ae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsfwalters/NEU-OB-MLP/blob/main/Clothing_Classification_with_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification of Clothing Items\n",
        "In this Colab notebook, you will build and train a neural network to classify a\n",
        "handwritten digit (zero through nine) in an image.  Run each cell by clicking on the play button or using keys `Shift+Enter`.  There will be some text hints and questions to help guide you through the notebook."
      ],
      "metadata": {
        "id": "ekwZYGQW32FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install dependencies\n",
        "# import libraries for this notebook\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "widWrvRqcto0",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download Data\n",
        "First, lets download the dataset.  The dataset is contains thousands of images of clothing items (shirts, pants, etc.).  In the next few code cells, you will generate some plots to better understand the dataset.  "
      ],
      "metadata": {
        "id": "0tLaZZQLijXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# download train and test sets\n",
        "train_data = FashionMNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "test_data = FashionMNIST(root='data', train=False, transform=ToTensor(), download=True)\n",
        "LABELS = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'boot']"
      ],
      "metadata": {
        "id": "lVWMPvjAipP_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Why do you need separate data for training and testing? What would happen if we only used training data?"
      ],
      "metadata": {
        "id": "7QymCYaW4ymf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print stats about datasets\n",
        "print(f'There are {len(train_data)} data points in train set' \\\n",
        "      f' and {len(test_data)} data points in test set.')\n",
        "\n",
        "# plot distribution of labels in train and test set\n",
        "plt.figure(figsize=(9, 4))\n",
        "plt.hist(train_data.targets, torch.arange(11)-0.7,\n",
        "         rwidth=0.4, density=True, label='Train Data')\n",
        "plt.hist(test_data.targets, torch.arange(11)-0.3,\n",
        "         rwidth=0.4, density=True, label='Test Data')\n",
        "plt.ylabel('Fraction of Examples', fontsize=14)\n",
        "plt.xticks(torch.arange(0,10), LABELS)\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=14)\n",
        "plt.title('Distribution of Clothing Items in Dataset', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8HoURYggDQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Why is it a good idea to have the data spread out over all labels?  "
      ],
      "metadata": {
        "id": "HPsMTo5hkxlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize images\n",
        "def plot_examples(train_data, test_data, label):\n",
        "  f, ax = plt.subplots(2, 10, figsize=(10,2))\n",
        "  f.subplots_adjust(0.1, 0, 1, 0.8, wspace=0.01, hspace=0.3)\n",
        "\n",
        "  ind = LABELS.index(label)\n",
        "  # find data points with correct label\n",
        "  train_imgs = train_data.data[train_data.targets == ind]\n",
        "  test_imgs = test_data.data[test_data.targets == ind]\n",
        "\n",
        "  for i in range(10):\n",
        "    ax[0,i].imshow(train_imgs[i], cmap='gray')\n",
        "    ax[0,i].axis('off')\n",
        "    ax[1,i].imshow(test_imgs[i], cmap='gray')\n",
        "    ax[1,i].axis('off')\n",
        "\n",
        "  plt.suptitle(f'Examples of \"{label}\" (y={ind})', fontweight='bold', fontsize=20)\n",
        "  ax[0,0].text(-10, 16, 'Train Images', ha='right', fontstyle='italic', fontsize=16)\n",
        "  ax[1,0].text(-10, 16, 'Test Images', ha='right', fontstyle='italic', fontsize=16)\n",
        "  plt.show()\n",
        "\n",
        "# try changing the DIGIT to see examples of different digits\n",
        "clothing_item = \"t-shirt\" # @param ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'boot']\n",
        "plot_examples(train_data, test_data, clothing_item)"
      ],
      "metadata": {
        "id": "20BBNo8PjRH5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Which clothing item do you think will be the hardest to recognize?  Are there any that could be easily confused? (change `clothing_item` in the above cell to see more examples; then hit the run button)\n",
        "\n",
        "[__Question__] What kind of variations do you see between items in the train data and test data? What kind of accuracy do you think will be possible?"
      ],
      "metadata": {
        "id": "NafQMROYlPMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model\n",
        "Now, we create the neural network."
      ],
      "metadata": {
        "id": "Fyk0M-IbilA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the image has 28^2 values\n",
        "INPUT_SIZE = 28 * 28\n",
        "\n",
        "# there are 10 digits to classify\n",
        "OUTPUT_SIZE = 10\n",
        "\n",
        "# this changes how much learning capacity the model will have\n",
        "# increasing this number will slow down training\n",
        "HIDDEN_SIZE = 24\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    # nn.ReLU(True),\n",
        "    # nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),\n",
        "    # nn.ReLU(True),\n",
        "    nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        ").cuda()\n",
        "\n",
        "# function to reset weights of the model\n",
        "def reset_weights(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "    m.reset_parameters()\n",
        "\n",
        "# The number of learnable values within the network\n",
        "num_weights =  sum(p.numel() for p in model.parameters())\n",
        "print(f\"This model has {num_weights:,} weights.\")\n",
        "\n",
        "# For comparison, here are the estimated number of neurons in different animals\n",
        "#   fruit fly :   100,000\n",
        "#   honey bee :   960,000\n",
        "#   frog :     16,000,000\n",
        "#   dog :   2,253,000,000\n",
        "#   human: 86,000,000,000\n",
        "# [source](https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons)"
      ],
      "metadata": {
        "id": "NV_JWMKlnHHA",
        "outputId": "316f11dc-1041-424a-dd03-9813fd3be5f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model has 19,690 weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Optional__] If you have extra time, you can try changing the network and see what effects it has on the accuracy.  For instance, `HIDDEN_SIZE` can be changed or you could uncomment lines 17 and 18 to add an additional layer."
      ],
      "metadata": {
        "id": "Tp6JDYnMmSca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train\n",
        "Now, we will train the model by iterating over the dataset and updating the weights of the model to improve the accuracy.  "
      ],
      "metadata": {
        "id": "FhHFbZUOimy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data, test_data, num_epochs, batch_size, learning_rate):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # create dataloaders\n",
        "  train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  log = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    t = time.perf_counter()\n",
        "\n",
        "    train_losses = []\n",
        "    for imgs, labels in train_dataloader:\n",
        "      imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred_labels = model(imgs)\n",
        "      loss = nn.CrossEntropyLoss()(pred_labels, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "    test_losses = []\n",
        "    for imgs, labels in test_dataloader:\n",
        "      imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "      pred_labels = model(imgs)\n",
        "      test_losses.append(loss.item())\n",
        "\n",
        "    elapsed_time = time.perf_counter() - t\n",
        "    log.append(dict(epoch=epoch,\n",
        "                    train_loss= sum(train_losses) / len(train_losses),\n",
        "                    test_loss= sum(test_losses) / len(test_losses),\n",
        "                    elapsed_time= elapsed_time,\n",
        "    ))\n",
        "    print('Epoch {epoch}: TRAIN LOSS={train_loss:.5f} | TEST LOSS={test_loss:.5f} | '\n",
        "          'time={elapsed_time:.1f} s'.format(**log[-1]))\n",
        "\n",
        "  return model, log\n",
        "\n",
        "def plot_learning_curves(log):\n",
        "  f = plt.figure()\n",
        "  f.subplots_adjust(0.1, 0.1, 0.9, 0.9, wspace=0.2)\n",
        "\n",
        "  epochs = [l['epoch'] for l in log]\n",
        "  train_loss = [l['train_loss'] for l in log]\n",
        "  test_loss = [l['test_loss'] for l in log]\n",
        "\n",
        "  plt.plot(epochs, train_loss, label='train')\n",
        "  plt.plot(epochs, test_loss, label='test')\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('Epoch', fontsize=16)\n",
        "  plt.ylabel('Loss', fontsize=16)\n",
        "  plt.legend(loc='upper right', fontsize=14)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NW1l4cpmj8CE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These values are called hyperparameters and are the 'dials' that we can turn\n",
        "# to try to improve the model's performance\n",
        "\n",
        "BATCH_SIZE = 512 # how many examples are shown to the network at a time\n",
        "NUM_EPOCHS = 10 # number of times the model sees the full dataset\n",
        "LEARNING_RATE = 0.005 # how much the neurons adjust their weights\n",
        "\n",
        "model.apply(reset_weights)\n",
        "\n",
        "# this trains the model, it should take around 10 seconds per epoch\n",
        "# an epoch means a full pass over the entire dataset\n",
        "model, log = train_model(\n",
        "  model, train_data, test_data, NUM_EPOCHS, BATCH_SIZE, LEARNING_RATE\n",
        ")\n",
        "\n",
        "plot_learning_curves(log)"
      ],
      "metadata": {
        "id": "2f4mgyXpmxQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Do you observe [overfitting](https://www.ibm.com/cloud/learn/overfitting)?\n",
        "\n",
        "[__Optional__] Try adjusting the hyperparameters.  For example, what happens when you double `LEARNING_RATE`?"
      ],
      "metadata": {
        "id": "5t_O937p9kqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluate Trained Model\n",
        "Now we find the accuracy of the trained model at classifying digits. By looking at some example predictions, you may get some insight into why the model makes mistakes."
      ],
      "metadata": {
        "id": "CpiqX3QQinnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_statistics(model, data):\n",
        "  labels = data.targets\n",
        "  loader = DataLoader(data, batch_size=256)\n",
        "\n",
        "  pred_labels = []\n",
        "  for imgs, _ in loader:\n",
        "    pred_labels.append(model(imgs.cuda()).max(1)[1].detach().cpu())\n",
        "\n",
        "  pred_labels = torch.cat(pred_labels)\n",
        "\n",
        "  is_correct = (labels == pred_labels).float()\n",
        "  for i in range(10):\n",
        "    ind = labels == i\n",
        "    acc = torch.mean( is_correct[ind] )\n",
        "    print(f'{LABELS[i]: <12}: {acc:.2%} accuracy')\n",
        "\n",
        "  total_acc = torch.mean( is_correct )\n",
        "  print(30*'-')\n",
        "  print(f'Total       : {total_acc:.2%} accuracy')\n",
        "\n",
        "\n",
        "DATA = test_data\n",
        "# DATA = train_data\n",
        "compute_statistics(model, DATA)"
      ],
      "metadata": {
        "id": "GGKOuhpAwwjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d856510-bb79-4fdc-e0f9-1152f3e45616"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-shirt     : 78.10% accuracy\n",
            "trouser     : 96.00% accuracy\n",
            "pullover    : 65.20% accuracy\n",
            "dress       : 89.70% accuracy\n",
            "coat        : 81.10% accuracy\n",
            "sandal      : 96.70% accuracy\n",
            "shirt       : 66.60% accuracy\n",
            "sneaker     : 90.20% accuracy\n",
            "bag         : 96.00% accuracy\n",
            "boot        : 93.20% accuracy\n",
            "------------------------------\n",
            "Total       : 85.28% accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] What clothing items are hardest to classify? Is there an explanation for this?\n",
        "\n",
        "[__Question__] What accuracy would you expect if the model had not learned anything?\n",
        "\n",
        "[__Question__] Do you think the accuracy would be higher or lower for images from the training data? (try it yourself by setting `DATA` to `train_data` above)"
      ],
      "metadata": {
        "id": "V6K-eG4e4vHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(model, data):\n",
        "  from matplotlib.patches import Rectangle\n",
        "  loader = DataLoader(data, batch_size=24, shuffle=True)\n",
        "\n",
        "  imgs, labels = next(iter(loader))\n",
        "  pred_labels = model(imgs.cuda()).max(1)[1].detach().cpu()\n",
        "\n",
        "  f, axs = plt.subplots(4,6, figsize=(10, 8))\n",
        "  f.subplots_adjust(0,0,1,1, wspace=0.1, hspace= 0.25)\n",
        "\n",
        "  for i, ax in enumerate(axs.flatten()):\n",
        "    ax.imshow(imgs[i,0], cmap='gray')\n",
        "    color = 'g' if pred_labels[i] == labels[i] else 'r'\n",
        "    ax.add_patch(Rectangle((0,0), 1, 1, fc='none', ec=color, lw=10, transform=ax.transAxes))\n",
        "\n",
        "    title = f'pred={LABELS[pred_labels[i]]}'\n",
        "    if pred_labels[i] != labels[i]:\n",
        "      title += f'\\n [{LABELS[labels[i]]}]'\n",
        "    ax.set_title(title, fontsize=14)\n",
        "    ax.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "# running this cell again will show new examples\n",
        "plot_predictions(model, test_data)"
      ],
      "metadata": {
        "id": "KSYUvEkBwzjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[__Question__] Do you see any patterns in the wrong predictions?\n",
        "\n",
        "[__Question__] Do you think the model is as good as a human at recognizing clothing items?"
      ],
      "metadata": {
        "id": "-CjU5pxB3K_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you have time, go back up to the Model section and see if you can modify the network to improve the prediction accuracy**"
      ],
      "metadata": {
        "id": "t3DY8Sb2OuEW"
      }
    }
  ]
}